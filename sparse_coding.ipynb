{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Coding Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the tutorial is to use Sparse Coding to understand the \"features\" which make-up handwritten digits. This sort of analysis is common when looking at natural signals (images) and also neuroscience data (LFP).\n",
    "\n",
    "Most of the code has already been written so you'll be running the code, looking at the plots, and manipulating some of the variables to understand how they affect the results. You should work in small groups (2-3) and go through the different sections of the notebook. Questions are highlighted in <font color='green'>green</font> throughout the notebook.\n",
    "\n",
    "We'll check-in occasionally to make sure everyone is making progress. Feel free to ask any of us questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using IPython Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython notebooks are made up of a number of 'cells'. Each cell can either run some python code or contain text.\n",
    "\n",
    "To run a cell, click on it or move to it with up and down arrows and press 'Shift + Enter'. Alternatively, you can press the 'play' button in the toolbar. Any output from the cell (text or plots) will apprear below the cell after you run it. Try running the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can do much in Python, you'll probably need to import one or a few libraries. NumPy is a matrix library that is used in scientific python applications. The 'import X as Y' statement loads a library X under the alias Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython can tell you about the properties of functions and modules/libraries. One way to get this is to 'tab complete'. Given a library, 'np', you can query the function in the library by typing 'np.' and pressing 'Tab'. Give it a try! You need have imported numpy for this information to be available, so before trying this make sure you've executed the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about a function, you can type the function's name then a question mark and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Only Sparse Coding on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements <font color='red'>**Positive Only**</font> <font color='purple'>**Sparse Coding**</font> on the <font color='blue'>**MNIST Dataset**</font>.\n",
    "\n",
    "Lets break that down! <font color='purple'>\n",
    "\n",
    "**Sparse Coding**</font> is an algorithm that seeks to disentangle the underlying generative factors of data. The result will be a set of \"dictionary elements\", akin to neuronal receptive fields, that represent these factors. \n",
    "<font color ='green'>**Can you guess what the factors would be for songs? for pictures? the emissions spectra of stars?**</font>\n",
    "<br><br>\n",
    "<font color='red'>**Positive-Only**</font> means that we don't allow our coefficients to be negative -- we prevent our neurons from firing \"negative spikes\" that correspond to the opposite of their receptive field. This makes the math a bit harder, but the results are easier to interpret. <br><br>\n",
    "\n",
    "<font color='blue'>**MNIST**</font> is the name of the dataset we'll be using, and it's one of the most widely used datatsets in the field of machine learning. It's a collection of hand-written digits, drawn from American high school students and census takers.  <font color ='green'>**Can you think of any applications for an algorithm trained on this dataset?**</font>\n",
    "\n",
    "Intuitively speaking, the underlying generative factors of digits are pen strokes. That is, when these strokes are combined in the right way, we get digits. We will see that sparse coding discovers this underlying structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Mathematical Interpretation\n",
    "In sparse coding, we define the following:\n",
    "\n",
    "$I$ is an image, $D$ is a dictionary of underlying generative factors (each with the same dimensionality as the input), and $A$ the sparse coefficients (one per dictionary element). \n",
    "\n",
    "In neuroscience terms, $I$ is our input from the retina, the dictionary $D$ is our set of receptive fields, and the coefficients $A$ are firing rates.\n",
    "\n",
    "We seek to write the *n*th image, $I_n$, as a weighted sum of the dictionary elements, $D_i$. \n",
    "\n",
    "Translating that into math gives us:\n",
    "\n",
    "$$I_n = D_1 * A_1(I_n) + D_2 * A_2(I_n) + \\ldots$$\n",
    "\n",
    "where the dictionary elements are the same for any image in the data set, and the coefficients, $A$, are different for each image. \n",
    "\n",
    "In order to learn the dictionary elements $D$, and the sparse coefficients, $A$, we minimize the following *cost function*, $C$:\n",
    "\n",
    "$$C = |I - \\sum_i A_i * D_i| ^ 2 + \\lambda \\sum_i A_i $$\n",
    "\n",
    "where $$ |D_i|^2 = 1$$ and $$ A_i ≥ 0 $$\n",
    "\n",
    "Note that this is a linear algebraic equation. The matrix $D$ has the shape number of dictionary elements by the number of pixels, which are the lengths of the activation and image vectors, respectively.\n",
    "\n",
    "Let's look at it piece-by-piece.\n",
    "\n",
    "A *cost function* is a mathematical construct that assigns a number, the cost, to any given state of our algorithm. The lower the cost is, the closer we are to achieving the goal of our algorithm -- that's why it's also called the *objective function*. It's a creature with many names$^†$!\n",
    "\n",
    "We have two competing goals, so we have two competing pieces in our cost function.\n",
    "\n",
    "The first part, $|I - \\sum_i A_i * D_i| ^ 2$, takes the dictionary elements, multiplies them by the coefficient values, and then subtracts that away from the image. The result is thus the part of the image that we haven't yet explained, or the *representation* or *reconstruction error*, and it is also the *squared error*.$^*$\n",
    "\n",
    "The second part, $ \\sum_i A_i $, adds up all of our activations. The more active we are, the worse we do on our objective function. This is our *sparseness penalty*.\n",
    "\n",
    "As I've explained it so far, reconstruction error and sparseness are weighted equally. In different situations, we might wish the make sparseness more or less important than the accuracy. To do this, we multiply the sparseness penalty by a parameter called &lambda;, or \"lambda\". Note that we could have just as easily multiplied the reconstruction error by a parameter called &zeta;! Higher values of &lambda; mean that we find sparser solutions, but do worse on fatihfully reproducing the input.\n",
    "\n",
    "Lastly, we have our two constraints. The constraint on $|D_i|^2$ gets rid of a possible redundancy in our equation. Without it, a small dictionary element multiplied by a large sparse coefficient is the same as a large dictionary element multiplied by a small sparse coefficient. By restricting the magnitude of the dictionary elements, we make sure that all the information about intensity goes into the coefficients. The other constraint is our <font color='red'>*positive only* </font> constraint -- activations must be positive!\n",
    "\n",
    "To minimize this function, we do the following steps:\n",
    "\n",
    "0. Randomly initialize $D$.\n",
    "\n",
    "1. Choose a batch of images $I$.\n",
    "\n",
    "2. Minimize$^‡$ $C$ with respect to $A$, holding $D$ fixed.\n",
    "\n",
    "3. *Keeping that value of $A$*, change $D$ by a really small amount to reduce the value of $C$.\n",
    "\n",
    "4. Return to step 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Interpretation\n",
    "In addition to being a useful tool for understanding data, sparse coding is also compelling because it provides a principle and a mechanism by which the sensory cortex might learn from stimuli.\n",
    "\n",
    "Step 3 is analagous to neurons integrating information $I$ and firing action potentials $A$. We call this the **Inference Step**. In the brain, this happens quickly in response to stimuli. Because the brain wishes to accurately represent the outside world, the neurons must seek to minimize the error of their representation, the first part of our equation. \n",
    "\n",
    "Because spiking is metabolically expensive (our big brains use up more than 25% of our calories!), we'd like to achieve a good representation with as few spikes as possible. If we do really well (fewer active neurons than pixels in the input), then we've also achieved compression, since our internal representation is smaller than the input. \n",
    "\n",
    "If you know a thing or two about information theory, then you might be astounded to discover that such a simple algorithm can discover compression schemes, which usually take very many, very clever computer scientists quite some time. You'll be even more astounded if you compare the results of sparse coding applied to natural images with the .PNG file format for storing images (look at the wavelets). They're incredibly similar!\n",
    "\n",
    "Step 4 is, then, analogous to synaptic plasticity. We call this the **Learning Step**. It causes changes in the neuronal receptive fields $D$ that allow those neurons to perform better at our stated objective -- the more images, the better. Another bonus question: <font color ='green'> what would happen if we just showed the same image over and over again? </font>\n",
    "\n",
    "#####Footnotes\n",
    "\n",
    "<font size ='2'> $^*$ Bonus question: <font color ='green'> why is the error squared? </font> (this is a question with more than one answer, and some of them are quite deep!)\n",
    "\n",
    "$^†$ There are many uses for this mathematical object, and each use has its own name. Statisticians call it a *loss function*. Economists and utilitarians flip it upside down and call it a *utility function* -- higher is better, so utility is maximized. Physicists use them to describe physical systems, where they become an *energy function*, and energy is always minimized -- balls roll down hills. There's a mathematical connection between all of these, but the math just expresses the way humans think -- magnets \"want\" to point north, while rational actors are \"compelled\" towards the optimal solution!\n",
    "<br> <br>\n",
    "$^‡$ You could do this with gradient descent, but we'll use a faster method called \"FISTA\" -- see the appendix to this document if you're curious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Let's Get Started!\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "We'll need numpy (matrix library) and matplotlib (plotting library) to do most of the heavy lifting. Additionally, we'll use a few tools from scipy (scientific computing) and ones that we've written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # NUMerical PYthon library, matrix library\n",
    "import matplotlib # Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline\n",
    "from scipy.io import loadmat # load .mat files\n",
    "from scipy.stats import probplot, expon, norm, halfnorm # Stats functionality\n",
    "\n",
    "from rf_plot import show_fields # code for plotting\n",
    "\n",
    "from network import Network # code for sparse-coding network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load Data\n",
    "First, we'll load the data and do a little preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_file = \"mnist.mat\"\n",
    "\n",
    "data = loadmat(data_file)\n",
    "IMAGES = data['IMAGES']\n",
    "LABELS = data['LABELS']\n",
    "\n",
    "# Set basic parameters\n",
    "(K, L_img, L_img) = IMAGES.shape\n",
    "print('Number of images: '+str(K))\n",
    "K # Number of base images\n",
    "L_img # Linear size of images from the data\n",
    "N_pix_img = L_img ** 2\n",
    "\n",
    "# Scale the images to have a constant standard deviation\n",
    "IMAGES = IMAGES / np.std(IMAGES.astype(float), axis = (1, 2), keepdims = True)\n",
    "data = IMAGES.reshape(-1, N_pix_img)\n",
    "order = np.random.permutation(data.shape[0]) # Permute the data since they are sorted by digit\n",
    "data = data[order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a few of the images from the dataset. Each images is a 14 by 14 image of a handwritten digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "show_fields(data[:81], cmap='gray_r', pos_only=True)\n",
    "plt.title('Images')\n",
    "p = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size = '3'> 1) Intuitively, what are handwritten digits 'made' out of?\n",
    "<br>\n",
    "2) Why is it okay to combine a collection of positive-only things to make handwritten digits?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create Sparse Coding Network\n",
    "Set some parameters for training the network and create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "N_sp = 81 # Number of sparse dictionary elements\n",
    "lamb = 0.5 # Sparsity parameter (0.5 is a good value, too large and you'll get NaNs)\n",
    "eta = 0.05 # Dictionary Learning Step Size\n",
    "\n",
    "net = Network(N_sp, N_pix_img, lamb, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the untrained dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "show_fields(net.D, cmap='gray_r',pos_only = True)\n",
    "plt.title('Untrained Dictionary')\n",
    "p = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A, costs = net.infer_A(data[0:100], n_g_steps=150, track_cost=True)\n",
    "plt.plot(np.log(costs))\n",
    "plt.title('Cost During Inference')\n",
    "plt.xlabel('Iteration')\n",
    "p = plt.ylabel('Log-Cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='3'>1) How was the dictionary initialized? What does the dictionary mean? What is the biological analogue for vision?\n",
    "<br>\n",
    "2) What is the inference step supposed to do? Is it working?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Train the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network and visualize the dictionary elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[MSE_hist, sparsity_hist, SNR_hist, cost_hist] = net.train(data, reset=False, batch_size=200, n_batches=50, eta = eta)\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(MSE_hist)\n",
    "plt.title('Reconstruction error during training')\n",
    "plt.xlabel('batch #')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(sparsity_hist)\n",
    "plt.title('Sparsity penalty during training')\n",
    "plt.xlabel('batch #')\n",
    "plt.ylabel('sparsity')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(cost_hist)\n",
    "plt.title('Total Cost during training')\n",
    "plt.xlabel('batch #')\n",
    "p = plt.ylabel('Cost')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dictionary elements. You can go back and run the training again (multiple times) and see how the plots change over time. Once all three plots above have become noisy horizontal lines, learning is complete. Since the right-most plot shows our total error, it is the most important one, and takes the longest to reach completion. You might need to run the training cell many times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "show_fields(net.D, cmap='gray_r', pos_only=True)\n",
    "plt.title('Trained Dictionary')\n",
    "p = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size='3'>1) What happens to the reconstruction error, sparsity penalty, and the cost during training?\n",
    "<br>\n",
    "2) What do the dictionary elements look like? What happens if you run the training cell multiple times? What happens to the dictionary as you train it more?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a sparse-coding network tried to reconstruct its input, we should be able to visualize the reconstructions in more detail for a particular image.\n",
    "\n",
    "You can run the following cell multiple times and it will plot a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "q = np.random.randint(net.A.shape[0])\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Reconstruction')\n",
    "plt.imshow(net.reconstruct(net.X, net.A)[q].reshape(L_img, L_img),\n",
    "           interpolation = 'nearest',\n",
    "           cmap = 'gray_r', vmin = 0, vmax = net.X[q].reshape(L_img, L_img).max())\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Orignal Image')\n",
    "plt.imshow(net.X[q].reshape(L_img, L_img),\n",
    "           interpolation = 'nearest',\n",
    "           cmap = 'gray_r')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 3)\n",
    "\n",
    "plt.hist(net.A[q])\n",
    "\n",
    "sort_idx = np.argsort(net.A[q])[::-1]\n",
    "N_active = np.sum(net.A[q] > 0.0)\n",
    "active_idx = sort_idx[0:N_active]\n",
    "\n",
    "plt.title('Histogram of Sparse Coefficients \\n Number active: %d' % N_active)\n",
    "plt.xlabel('Coefficient Value')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "show_fields(net.D[active_idx] * \n",
    "            net.A[q][active_idx][:, np.newaxis], \n",
    "            cmap = 'gray_r', pos_only = True)\n",
    "plt.title('Active Dictionary Elements \\n Scaled by their activations')\n",
    "p = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green', size='3'>1 ) How well is the network reconstructing the image?\n",
    "<br>\n",
    "2) How are the coefficient values distributed? Why are they distributed this way?\n",
    "<br>\n",
    "3) How is the bottom-right plot related to the reconstruction?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the joint statistics between different sparse coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_digits = 10000\n",
    "A = net.infer_A(data[np.random.randint(0, data.shape[0], n_digits), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n1, n2 = np.random.permutation(net.A.shape[1])[:2]\n",
    "_ = plt.hist2d(A[:,n1], A[:,n2], 20, norm=LogNorm())\n",
    "plt.colorbar()\n",
    "plt.xlabel('Neuron '+str(n2))\n",
    "p = plt.ylabel('Neuron '+str(n1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>1) How are the coefficients distributed? Everytime you run the plot, it will choose a different pair of neurons.\n",
    "<br>\n",
    "2) What would this plot look like if the coefficients were from a normal distribution?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the distribution of sparse coefficients (firing rates), we can compare them with different distribution. One tool for doing this is a probability plot. This plot compares the ordered value from the data to the ordered values the distribution. Closer to the red line is better (note the $R^2$ value at the bottom right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "As = net.A.ravel()\n",
    "p = probplot(As[As > 0], dist=expon, plot=plt)\n",
    "plt.xlabel('Ordered Values from Distribution')\n",
    "p = plt.ylabel('Ordered Values from Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>1) How well does the distribution line up with samples drawn from an exponential distribution?\n",
    "<br>\n",
    "2) How well does it match if you change \"expon\" to \"norm\" or \"halfnorm\"?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap: Changing &lambda;<br>\n",
    "<font color='green' size ='3'> If you have time left, go back and change &lambda; to be larger or smaller. Otherwise, move on to the next section.<br>\n",
    "1) What happens to the sparsity? What happens to the reconstruction error? <br>\n",
    "2) What do the dictionaries look like?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Finale: Natural Images\n",
    "\n",
    "We will close out today by recapitulating the work that led to Olshausen and Field's 1997 Nature paper, \"Emergence of simple-cell receptive field properties by learning a sparse code for natural images\".\n",
    "\n",
    "There are just a few differences to keep in mind. \n",
    "\n",
    "First, we'll be using the original version of the algorithm, rather than the positive-only version. As such, our dictionary elements and our activations will be allowed to take on negative values. This means we have to slightly alter the cost function: rather than just adding up the activations, we'll add up their absolute values, so that we still penalize negative activations.\n",
    "\n",
    "Second, when images come in to the visual cortex, they have already been processed by the retina and by the lateral geniculate nucleus of the thalamus. For our algorithm to capture exactly what V1 does, we need to mimic that processing. This processing is called \"whitening\". If you're interested in more information about the neuroscientific evidence for whitening, check out <a href=\"http://www.jneurosci.org/content/16/10/3351.full.pdf\">Yang Dan's 1996 paper with Clay Reid</a>. If you'd like more information about whitening as a mathematical process, just ask one of us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading in the dataset, a collection of pictures David Field took while on vacation in Alaska. We then proceed to pull out 12 pixel by 12 pixel patches. One reason to do this is because handling full 512x512 images is computationally expensive. <font color='green'> Can you think of another reason to use smaller patches? HINT: how large would the useful pieces for building large images be? Think retinotopy. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### IMPORT IMAGES, EXTRACT PATCHES ###\n",
    "\n",
    "import random\n",
    "\n",
    "#load in data\n",
    "data_file = \"IMAGES.mat\"\n",
    "data = loadmat(data_file)\n",
    "IMAGESin = data['IMAGES'];\n",
    "\n",
    "#calculate a few properties\n",
    "patchArea = 144 #12x12 pixel patches\n",
    "sz = np.sqrt(patchArea)\n",
    "numPatches= 10000 #set to whatever large number you like\n",
    "imageDimension  = [0,0] #initialize\n",
    "(imageDimension[0],imageDimension[1],numImages) = IMAGESin.shape\n",
    "IMAGES = np.zeros((numPatches,sz,sz,))\n",
    "\n",
    "#extract patches\n",
    "for i in range(numPatches):\n",
    "    r = np.ceil((imageDimension[0]-sz) * random.uniform(0, 1))\n",
    "    c = np.ceil((imageDimension[1]-sz) * random.uniform(0, 1))\n",
    "    imIndex = np.ceil(numImages * random.uniform(0, 1)) \n",
    "    IMAGES[i,:,:] = np.reshape(IMAGESin[r:r+sz, c:c+sz, imIndex-1],(sz,sz))\n",
    "    #plt.imshow(IMAGES[:,:,1],cmap='gray',interpolation='none')\n",
    "\n",
    "# Set basic parameters\n",
    "(K, L_img, L_img) = IMAGES.shape\n",
    "print('Number of patches: '+str(K))\n",
    "K # Number of base images\n",
    "L_img # Linear size of images from the data\n",
    "N_pix_img = L_img ** 2\n",
    "\n",
    "# Scale the images to have a constant standard deviation\n",
    "IMAGES = IMAGES / np.std(IMAGES.astype(float), axis = (1, 2), keepdims = True)\n",
    "data = IMAGES.reshape(-1,N_pix_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at an example image and some of the patches we'll be trying to reconstruct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show an example image\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(IMAGESin[:,:,1],cmap='gray',interpolation='nearest')\n",
    "plt.title('A Natural Image, After Retinal Processing')\n",
    "p = plt.axis('off')\n",
    "\n",
    "#show some of the patches\n",
    "plt.figure(figsize=(6,6))\n",
    "show_fields(data[:81], cmap='gray')\n",
    "plt.title('Patches Taken From Natural Images')\n",
    "p = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to set up our network to handle this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### NETWORK SETUP ####\n",
    "\n",
    "OC=1 #you'll get a chance to change this for one of the questions\n",
    "#but don't go above 4 unless you want to wait a long time!\n",
    "\n",
    "pos_only=False\n",
    "N_sp = sz*sz*OC # Number of sparse dictionary elements\n",
    "lamb = 0.5 # Sparsity parameter (0.5 is a good value, too large and you'll get NaNs)\n",
    "eta = 0.05 # Dictionary Learning Step Size\n",
    "net2 = Network(N_sp, N_pix_img, lamb, eta,pos_only=pos_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now let's do the full algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[MSE_hist, sparsity_hist, SNR_hist, cost_hist] = net2.train(data, reset=False, batch_size=250, n_batches=50, eta = eta)\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(MSE_hist)\n",
    "plt.title('Reconstruction error during training')\n",
    "plt.xlabel('batch #')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(sparsity_hist)\n",
    "plt.title('Sparsity penalty during training')\n",
    "plt.xlabel('batch #')\n",
    "plt.ylabel('sparsity')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(cost_hist)\n",
    "plt.title('Total Cost during training')\n",
    "plt.xlabel('batch #')\n",
    "p = plt.ylabel('Cost')\n",
    "\n",
    "plt.figure(figsize=(5*OC,5*OC)) #if the figures don't fit on your screen, change 5 to a smaller integer\n",
    "show_fields(net2.D, cmap='gray',pos_only=pos_only)\n",
    "plt.title('Dictionary Trained on Natural Image Patches')\n",
    "p = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size ='3'> <br>\n",
    "1) Check out Figure 4 in <a href=\"http://www.nature.com/nature/journal/v381/n6583/pdf/381607a0.pdf\"> Olshausen and Field's 1997 paper</a>. Do your dictionary elements look similar?  <br>\n",
    "2) Head to <a href=\"http://www.cns.nyu.edu/csh/csh06/PDFs/Ringach2002b.pdf\">Dario Ringach's 2002 paper</a> on simple cells in macaque V1 and take a look at Figure 4, which shows the classes of receptive fields they detected. Try and find a dictionary element for each class. If there are any classes that you can't find, try increasing the value of the variable \"OC\" above, which adds more elements to your dictionary. Note that increasing this number makes training take much longer! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Appendix: Details on FISTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the objective function has an absolute value, typical gradient descent approaches converge slowly. Thus there are special purpose gradient descent methods that minimize functions that are in the form $$f(x) + g(x)$$ where $f(x)$ is a continuously differentiable, convex function and $g(x)$ is a convex, but not continuously differentiable function, such as $g(x) = \\alpha |x|$. One such method is called FISTA, or the Fast Iterative Shrinkage-Threshold Algorithm. \n",
    "\n",
    "The core kernel of the FISTA algorithm is the ISTA step:\n",
    "\n",
    "Define\n",
    "$$p_L(y) = \\text{argmin}_x \\, g(x) + L/2 * ||x- g(y)||^2$$ where $$g(y) = y - \\frac{1}{L} \\nabla f(y)$$\n",
    "\n",
    "and where $L$ is the constant such that $$||\\nabla f(x) - \\nabla f(y)|| \\le L ||x - y||$$\n",
    "\n",
    "When $g(x) = \\alpha|x|_1$, then $$p_L(y) = h_\\theta(g(y))\\qquad h_\\theta(y) = \\text{sign}(y)(|y|-\\theta)\\qquad \\theta = \\frac{\\alpha}{L}$$\n",
    "$h$ is applied pointwise its input and is called the shrinkage function. Simplying calculating $x_{t+1} = p_L(x_t)$ is the ISTA algorithm. If we more intelligently choose our new value to probe our function, then we get faster convergence. The FISTA algorithm is as follows:\n",
    "\n",
    "1. Initialize $y_0 = x_0 = X0$, $t_0=1$. \n",
    "\n",
    "2. For $k \\ge 0$, iterate the following:\n",
    "\n",
    "$$x_{k+1} = p_L(y_k)\\qquad t_{k+1} = 0.5 * (1 + \\sqrt{1 + 4 * t_k ^2})\\qquad y_{k+1} = x_{k+1} + \\frac{t_k - 1}{t_{k+1}} * (x_{k+1} - x_k)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
