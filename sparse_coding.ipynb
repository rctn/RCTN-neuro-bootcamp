{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using IPython Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython notebooks are made up of a number of 'cells'. Each cell can either run some python code or contain text.\n",
    "\n",
    "To run a cell, click on it or move to it with up and down arrows and press 'Shift + Enter'. Alternatively, you can press the 'play' button in the toolbar. Any output from the cell (text or plots) will apprear below the cell after you run it Try running the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Hello World!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can do much in Python, you'll probably need to import one or a few libraries. NumPy is a matrix library that is used in scientific python applications. The 'import X as Y' statement loads a library X under the alias Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython can tell you about the properties of functions and modules/libraries. One way to get this is to 'tab complete'. Given a library, 'np', you can query the function in the library by typing 'np.' and pressing 'Tab'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about a function, you can type the functions name then a question mark and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Only Sparse Coding on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements Positive Only Sparse Coding on MNIST.\n",
    "\n",
    "Lets break that down.\n",
    "\n",
    "Sparse Coding is an algorithm that seeks to disentangle the underlying generative factors of data. In this particular case, we are considering the dataset, MNIST, which is a collection of digits. Intuitively speaking, the underlying generative factors of digits are pen strokes. When these strokes are combined in the right way, we get digits. We will see that sparse coding discovers this underlying structure. \n",
    "\n",
    "In sparse coding, we define the following:\n",
    "$I$ is an image, $D$ is a dictionary of underlying generative factors, and $A$ the sparse coefficients. We seek to write our image as a weighted sum of the dictionary elements. In equation form, \n",
    "\n",
    "$$I(x) = d_1(x) * a_1 + d_2(x) * a_2 + \\ldots$$\n",
    "\n",
    "where the dictionary elements are the same for any image in the data set, and the coefficients, $a$, are different for each image. \n",
    "\n",
    "In order to learn the dictionary elements $D$, and the sparse coefficients, $A$, we minimize the following objective function:\n",
    "\n",
    "$$E = |I - A * D| ^ 2 + |A|_1 \\qquad \\sum_x d_i(x)^2 = 1$$\n",
    "\n",
    "(Note $D$ is number of dictionary elements by the number of pixels). To minimize this function, we do the following steps:\n",
    "\n",
    "0. Choose an initial value of $D$.\n",
    "\n",
    "1. Choose a batch of images $I$.\n",
    "\n",
    "2. Minimize $E$ with respect to $A$ - we use FISTA which is a slighly better version of gradient descent.\n",
    "\n",
    "3. Keeping that value of $A$, change $D$ one gradient step to reduce the value of $E$.\n",
    "\n",
    "4. Return to step 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (8,8)\n",
    "from scipy.io import savemat, loadmat\n",
    "from scipy.stats import probplot, expon\n",
    "\n",
    "from utils.rf_plot import show_fields\n",
    "\n",
    "from network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "data_file = \"mnist.mat\"\n",
    "output_dir = 'output/'\n",
    "\n",
    "data = loadmat(data_dir + data_file)\n",
    "IMAGES = data['IMAGES']\n",
    "LABELS = data['LABELS']\n",
    "\n",
    "# Set basic parameters\n",
    "(K, L_img, L_img) = IMAGES.shape\n",
    "print('Number of images: '+str(K))\n",
    "K # Number of base images\n",
    "L_img # Linear size of images from the data\n",
    "N_pix_img = L_img ** 2\n",
    "\n",
    "# Scale the images to have a constant standard deviation\n",
    "IMAGES = IMAGES / np.std(IMAGES.astype(float), axis = (1, 2), keepdims = True)\n",
    "data = IMAGES.reshape(-1, N_pix_img)\n",
    "order = np.random.permutation(data.shape[0]) # Permute the data since they are sorted by digit\n",
    "data = data[order]\n",
    "\n",
    "pos_only = True # Positive Only Sparse coding if True\n",
    "N_sp = 81 # Number of sparse dictionary elements\n",
    "lamb = 0.5 # Sparsity parameter (0.5 is a good value, too large and you'll get NaNs)\n",
    "eta = 0.05 # Dictionary Learning Step Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sparse Coding Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Network(N_sp, N_pix_img, lamb, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the untrained dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_fields(net.D, pos_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the functions in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A, costs = net.infer_A(data[0:100], n_g_steps=150, track_cost=True)\n",
    "plt.plot(np.log(costs))\n",
    "plt.title('Cost During Inference')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Log-Cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network and visualize the dictionary elements. Run the cell multiple times to train it more (or change the n_epochs parameter). Then plot the dictionary elements again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.train(data[:10000], reset=False, n_epochs=1, eta = eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_fields(net.D, cmap='gray', pos_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the reconstructions in more detail for a particular image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = np.random.randint(net.A.shape[0])\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Reconstruction')\n",
    "plt.imshow(net.reconstruct(net.X, net.A)[q].reshape(L_img, L_img),\n",
    "           interpolation = 'nearest',\n",
    "           cmap = plt.cm.gray, vmin = 0, vmax = net.X[q].reshape(L_img, L_img).max())\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Orignal Image')\n",
    "plt.imshow(net.X[q].reshape(L_img, L_img),\n",
    "           interpolation = 'nearest',\n",
    "           cmap = plt.cm.gray)\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 3)\n",
    "\n",
    "plt.hist(net.A[q])\n",
    "\n",
    "sort_idx = np.argsort(net.A[q])[::-1]\n",
    "N_active = np.sum(net.A[q] > 0.0)\n",
    "active_idx = sort_idx[0:N_active]\n",
    "\n",
    "plt.title('Histogram of sparse Coefficients: \\n Number of active coefficients %d' % N_active)\n",
    "plt.xlabel('Coefficient Activity')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "show_fields(net.D[active_idx] * \n",
    "            net.A[q][active_idx][:, np.newaxis], \n",
    "            cmap = plt.cm.gray, pos_only = True)\n",
    "plt.title('Active Dictionary Elements \\n Scaled by their activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the joint statistics between different sparse coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert code here: make a scatter plot of (a1, a2) for different images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the distribution of non-zero coefficients is exponentially distributed using a probability plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "As = net.A.ravel()\n",
    "p = probplot(As[As > 0], dist = expon, plot = plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details on FISTA:\n",
    "\n",
    "Since the objective function has an absolute value, typical gradient descent approaches converge slowly. Thus there are special purpose gradient descent methods that minimize functions that are in the form $$f(x) + g(x)$$ where $f(x)$ is a continuously differentiable, convex function and $g(x)$ is a convex, but not continuously differentiable function, such as $g(x) = \\alpha |x|$. One such method is called FISTA, or the Fast Iterative Shrinkage-Threshold Algorithm. \n",
    "\n",
    "The core kernel of the FISTA algorithm is the ISTA step:\n",
    "\n",
    "Define\n",
    "$$p_L(y) = \\text{argmin}_x \\, g(x) + L/2 * ||x- g(y)||^2$$ where $$g(y) = y - \\frac{1}{L} \\nabla f(y)$$\n",
    "\n",
    "and where $L$ is the constant such that $$||\\nabla f(x) - \\nabla f(y)|| \\le L ||x - y||$$\n",
    "\n",
    "When $g(x) = \\alpha|x|_1$, then $$p_L(y) = h_\\theta(g(y))\\qquad h_\\theta(y) = \\text{sign}(y)(|y|-\\theta)\\qquad \\theta = \\frac{\\alpha}{L}$$\n",
    "$h$ is applied pointwise its input and is called the shrinkage function. Simplying calculating $x_{t+1} = p_L(x_t)$ is the ISTA algorithm. If we more intelligently choose our new value to probe our function, then we get faster convergence. The FISTA algorithm is as follows:\n",
    "\n",
    "1. Initialize $y_0 = x_0 = X0$, $t_0=1$. \n",
    "\n",
    "2. For $k \\ge 0$, iterate the following:\n",
    "\n",
    "$$x_{k+1} = p_L(y_k)\\qquad t_{k+1} = 0.5 * (1 + \\sqrt{1 + 4 * t_k ^2})\\qquad y_{k+1} = x_{k+1} + \\frac{t_k - 1}{t_{k+1}} * (x_{k+1} - x_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#savemat(output_dir + 'mnist_dictionary.mat', \n",
    "#        {'D': t_D.get_value(), 'Alpha': Alpha,\n",
    "#         'Algorithm': 'FISTA', 'Normalization': 'Equal Standard Deviation'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
