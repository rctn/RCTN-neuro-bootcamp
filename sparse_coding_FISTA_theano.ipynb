{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using IPython Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython notebooks are made up of a number of 'cells'. Each cell can either run some python code or contain text.\n",
    "\n",
    "To run a cell, click on it or move to it with up and down arrows and press 'Shift + Enter'. Alternatively, you can press the 'play' button in the toolbar. Any output from the cell (text or plots) will apprear below the cell after you run it Try running the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print \"Hello World!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can do much in Python, you'll probably need to import one or a few libraries. NumPy is a matrix library that is used in scientific python applications. The 'import X as Y' statement loads a library X under the alias Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython can tell you about the properties of functions and modules/libraries. One way to get this is to 'tab complete'. Given a library, 'np', you can query the function in the library by typing 'np.' and pressing 'Tab'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-a58a88215da2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-a58a88215da2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    np.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "np."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about a function, you can type the functions name then a question mark and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.zeros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Only Sparse Coding on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements Positive Only Sparse Coding on MNIST.\n",
    "\n",
    "Lets break that down.\n",
    "\n",
    "Sparse Coding is an algorithm that seeks to disentangle the underlying generative factors of data. In this particular case, we are considering the dataset, MNIST, which is a collection of digits. Intuitively speaking, the underlying generative factors of digits are pen strokes. When these strokes are combined in the right way, we get digits. We will see that sparse coding discovers this underlying structure. \n",
    "\n",
    "In sparse coding, we define the following:\n",
    "$I$ is an image, $D$ is a dictionary of underlying generative factors, and $A$ the sparse coefficients. In long form, \n",
    "\n",
    "$$I(x) = d_1(x) * a_1 + d_2(x) * a_2 + \\ldots$$\n",
    "\n",
    "where the dictionary elements are the same for any image in the data set, and the coefficients, $a$, are different for each image. \n",
    "\n",
    "In order to learn the dictionary elements $D$, and the sparse coefficients, $A$, we minimize the following objective function:\n",
    "\n",
    "$$E = |I - A * D| ^ 2 + |A|_1 \\qquad \\sum_x d_i(x) = 1$$\n",
    "\n",
    "(Note $D$ is number of dictionary elements by the number of pixels). To minimize this function, we do the following steps:\n",
    "\n",
    "0. Choose an initial value of $D$.\n",
    "\n",
    "1. Choose a batch of images $I$.\n",
    "\n",
    "2. Minimize $E$ with respect to $A$ - we use FISTA which is a slighly better version of gradient descent.\n",
    "\n",
    "3. Keeping that value of $A$, reduce $E$ by one gradient step in the direction of $\\nabla_D E$. \n",
    "\n",
    "4. Return to step 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.io import savemat, loadmat\n",
    "from scipy.stats import probplot, expon\n",
    "\n",
    "from utils.rf_plot import show_fields\n",
    "\n",
    "from network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 60000\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/\"\n",
    "data_fil = \"mnist.mat\"\n",
    "output_dir = 'output/'\n",
    "\n",
    "data = loadmat(data_dir + data_fil)\n",
    "IMAGES = data['IMAGES']\n",
    "LABELS = data['LABELS']\n",
    "\n",
    "# Set basic parameters\n",
    "(K, L_img, L_img) = IMAGES.shape\n",
    "print('Number of images: '+str(K))\n",
    "K # Number of base images\n",
    "L_img # Linear size of images from the data\n",
    "N_pix_img = L_img ** 2\n",
    "\n",
    "# Scale Images to have standard deviation one\n",
    "IMAGES = IMAGES / np.std(IMAGES.astype(float), axis = (1, 2), keepdims = True)\n",
    "data = IMAGES.reshape(60000, 14 * 14) # FIXME\n",
    "\n",
    "pos_only = True # Positive Only Sparse coding if True\n",
    "N_sp = 81 # Number of sparse dictionary elements\n",
    "lamb = 0.01 # coefficient for the sparse coefficients\n",
    "eta = 0.01 # Dictionary Learning Step Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sparse Coding Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Network(N_sp, N_pix_img, lamb, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.462770732\n",
      "79.777919671\n",
      "79.7066654721\n",
      "79.6997656647\n",
      "79.698510812\n",
      "79.6982785892\n",
      "79.6982396807\n",
      "79.6982301096\n",
      "79.6982239844\n",
      "79.6982201046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -2.31969396e+00,  -1.00446510e-01,  -3.36523322e-01, ...,\n",
       "         -7.49618053e-01,   2.42939274e+00,  -1.06487341e+00],\n",
       "       [ -1.95277891e+00,  -1.19886899e+00,  -1.12818603e+00, ...,\n",
       "         -5.82655240e-01,   3.57340892e+00,  -7.97927878e-01],\n",
       "       [ -1.85314216e+00,  -3.94823691e-01,   1.19846855e+00, ...,\n",
       "         -1.53605406e+00,   3.25516039e-01,   2.12325818e-03],\n",
       "       ..., \n",
       "       [ -1.18999544e+00,  -1.23165292e+00,   4.18561189e-01, ...,\n",
       "         -3.27891162e-01,   1.80302949e+00,  -9.38192452e-01],\n",
       "       [ -2.19576683e+00,  -0.00000000e+00,  -3.35814004e-01, ...,\n",
       "         -1.81545693e+00,   1.70621511e+00,   6.72662056e-01],\n",
       "       [ -8.32864139e-01,  -3.11845410e-01,  -1.11915023e+00, ...,\n",
       "         -5.51647989e-01,   3.91625797e+00,  -6.46811169e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.infer_A(data[0:100], n_g_steps=150, track_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the functions in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I_idx = train(100, Alpha, 0.2, cost_list, show_costs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I_idx = train(100, Alpha, 0.1, cost_list, show_costs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I_idx = train(100, Alpha, 0.03, cost_list, show_costs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I_idx = train(1, Alpha, 0.01, cost_list, show_costs=False, N_g_itr = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.log(np.array(cost_list)))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Log(cost)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "show_fields(t_D.get_value(), cmap = plt.cm.gray, pos_only = True)\n",
    "#plt.savefig(output_dir + 'mnist_basis.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "q = np.random.randint(N_bat)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Reconstruction')\n",
    "plt.imshow(np.dot(t_A.get_value(), t_D.get_value())[q].reshape(L_pat, L_pat),\n",
    "           interpolation = 'nearest',\n",
    "           cmap = plt.cm.gray, vmin = 0, vmax = t_I.get_value()[I_idx][q].reshape(L_pat, L_pat).max())\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Orignal Image')\n",
    "plt.imshow(t_I.get_value()[I_idx][q].reshape(L_pat, L_pat),\n",
    "           interpolation = 'nearest',\n",
    "           cmap = plt.cm.gray)\n",
    "plt.colorbar()\n",
    "plt.subplot(2, 2, 3)\n",
    "\n",
    "plt.hist(t_A.get_value()[q])\n",
    "\n",
    "sort_idx = np.argsort(t_A.get_value()[q])[::-1]\n",
    "N_active = np.sum(t_A.get_value()[q] > 0.0)\n",
    "active_idx = sort_idx[0:N_active]\n",
    "\n",
    "plt.title('Histogram of sparse Coefficients: \\n Number of active coefficients %d' % N_active)\n",
    "plt.xlabel('Coefficient Activity')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "show_fields(t_D.get_value()[active_idx] * \n",
    "            t_A.get_value()[q][active_idx][:, np.newaxis], \n",
    "            cmap = plt.cm.gray, pos_only = True)\n",
    "plt.title('Active Dictionary Elements \\n Scaled by their activations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "As = t_A.get_value().ravel()\n",
    "probplot(As[As > 0], dist = expon, plot = plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details on FISTA:\n",
    "\n",
    "Since the objective function has an absolute value, typical gradient descent approaches converge slowly. Thus there are special purpose gradient descent methods that minimize functions that are in the form $$f(x) + g(x)$$ where $f(x)$ is a continuously differentiable, convex function and $g(x)$ is a convex, but not continuously differentiable function, such as $g(x) = \\alpha |x|$. One such method is called FISTA, or the Fast Iterative Shrinkage-Threshold Algorithm. \n",
    "\n",
    "The core kernel of the FISTA algorithm is the ISTA step:\n",
    "\n",
    "Define\n",
    "$$p_L(y) = \\text{argmin}_x \\, g(x) + L/2 * ||x- g(y)||^2$$ where $$g(y) = y - \\frac{1}{L} \\nabla f(y)$$\n",
    "\n",
    "and where $L$ is the constant such that $$||\\nabla f(x) - \\nabla f(y)|| \\le L ||x - y||$$\n",
    "\n",
    "When $g(x) = \\alpha|x|_1$, then $$p_L(y) = h_\\theta(y)\\qquad h_\\theta(y) = \\text{sign}(y)(|y|-\\theta)\\qquad \\theta = \\frac{\\alpha}{L}$$\n",
    "$h$ is applied pointwise to $y$ and is the shrinkage function. Simplying calculating $x_{t+1} = p_L(x_t)$ is the ISTA algorithm. If we more intelligently choose our new value to probe our function, then we get faster convergence. The FISTA algorithm is as follows:\n",
    "\n",
    "1. Initialize $y_0 = x_0 = X0$, $t_0=1$. \n",
    "\n",
    "2. For $k \\ge 0$, iterate the following:\n",
    "\n",
    "$$x_{k+1} = p_L(y_k)\\qquad t_{k+1} = 0.5 * (1 + \\sqrt{1 + 4 * t_k ^2})\\qquad y_{k+1} = x_{k+1} + \\frac{t_k - 1}{t_{k+1}} * (x_{k+1} - x_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#savemat(output_dir + 'mnist_dictionary.mat', \n",
    "#        {'D': t_D.get_value(), 'Alpha': Alpha,\n",
    "#         'Algorithm': 'FISTA', 'Normalization': 'Equal Standard Deviation'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
